{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use bottleneck features and cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import numpy as np\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from keras.applications import ResNet50, InceptionResNetV2\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.callbacks import Callback, LearningRateScheduler\n",
    "from keras.optimizers import SGD\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get top labels\n",
    "get labels with more data in it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "df = pd.read_csv('data2/labels.csv')\n",
    "\n",
    "# get top 10 breed\n",
    "breed = df.groupby(['breed'])['breed'].count().nlargest(num_classes)\n",
    "breed = [i for i in breed.index]  # get index name only\n",
    "\n",
    "# labels in breed\n",
    "labels = df[df['breed'].isin(breed)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing data and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROWS = 250\n",
    "COLS = 250\n",
    "CHANNELS = 3\n",
    "CORE = 4\n",
    "\n",
    "\n",
    "def resize_img(file_path):\n",
    "    img = cv2.imread(file_path, cv2.IMREAD_COLOR)\n",
    "    return cv2.resize(img, (ROWS, COLS), interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "\n",
    "def prep_data(images):\n",
    "    count = len(images)\n",
    "    data = np.ndarray((count, ROWS, COLS, CHANNELS), dtype=np.uint8)\n",
    "\n",
    "    with ProcessPoolExecutor(max_workers=CORE) as executor:\n",
    "        data[:] = list(executor.map(resize_img, images))\n",
    "    \n",
    "    return data\n",
    "\n",
    "\n",
    "lb = LabelBinarizer()\n",
    "\n",
    "files = ['data2/train/%s.jpg' % i['id'] for _, i in labels.iterrows()]\n",
    "text_labels = [i['breed'] for _, i in labels.iterrows()]\n",
    "\n",
    "x = prep_data(files)\n",
    "y = lb.fit_transform(text_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1141/1141 [==============================] - 648s 568ms/step\n"
     ]
    }
   ],
   "source": [
    "inc = ResNet50(include_top=False, weights='imagenet')\n",
    "\n",
    "features = inc.predict(x, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model And Train evaluate function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(x_train, y_train, x_valid, y_valid):\n",
    "    model = Sequential()\n",
    "    model.add(Flatten(input_shape=features.shape[1:]))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    sgd = SGD(lr=0.01, momentum=0.9)\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=sgd,\n",
    "                  metrics=['categorical_accuracy'])\n",
    "    \n",
    "    model.fit(\n",
    "        x_train, y_train,\n",
    "        epochs=10,\n",
    "        validation_data=(x_valid, y_valid),\n",
    "        verbose=0\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perforn Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115/115 [==============================] - 0s 67us/step\n",
      "0.184110214399 0.947826087993\n",
      "114/114 [==============================] - 0s 62us/step\n",
      "0.0865268224805 0.964912280702\n",
      "114/114 [==============================] - 0s 62us/step\n",
      "1.6804974121 0.868421049494\n",
      "114/114 [==============================] - 0s 90us/step\n",
      "0.228603020049 0.938596487045\n",
      "114/114 [==============================] - 0s 58us/step\n",
      "0.180674313192 0.929824557221\n",
      "114/114 [==============================] - 0s 59us/step\n",
      "0.226556450651 0.929824557221\n",
      "114/114 [==============================] - 0s 120us/step\n",
      "0.167000009695 0.956140346694\n",
      "114/114 [==============================] - 0s 60us/step\n",
      "0.157356351614 0.929824557221\n",
      "114/114 [==============================] - 0s 58us/step\n",
      "0.289829286828 0.912280697572\n",
      "114/114 [==============================] - 0s 143us/step\n",
      "0.173595475 0.938596488091\n",
      "--------------------------------\n",
      "final loss and accuracy: 0.086526822480536475 0.96491228070175439\n"
     ]
    }
   ],
   "source": [
    "skf = KFold(n_splits=10, shuffle=False)\n",
    "\n",
    "smallest_loss = None\n",
    "most_acc = None \n",
    "best_train_index = None\n",
    "best_valid_index = None\n",
    "best_model = None\n",
    "\n",
    "for train_index, valid_index in skf.split(x, y):    \n",
    "    x_train, x_valid = features[train_index], features[valid_index]\n",
    "    y_train, y_valid = y[train_index], y[valid_index]\n",
    "    \n",
    "    model = create_model(x_train, y_train, x_valid, y_valid)\n",
    "    \n",
    "    loss, acc = model.evaluate(x_valid, y_valid)\n",
    "\n",
    "    if not smallest_loss or smallest_loss > loss:\n",
    "        smallest_loss = loss\n",
    "        most_acc = acc\n",
    "        best_train_index = train_index\n",
    "        best_valid_index = valid_index\n",
    "        best_model = Model\n",
    "        \n",
    "    print(loss, acc)\n",
    "\n",
    "print('--------------------------------')\n",
    "print('final loss and accuracy: %r %r' % (smallest_loss, most_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
